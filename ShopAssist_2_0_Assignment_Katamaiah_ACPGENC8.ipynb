{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katamaiah/shopassist-assignment/blob/main/ShopAssist_2_0_Assignment_Katamaiah_ACPGENC8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eguaFqDYns6q"
      },
      "source": [
        "## ShopAssist AI 2.0\n",
        "\n",
        "Combined function calling API with the ShopAssist AI 2.0's system design to make it more seamless,  less lines of code and cost efficient\n",
        "\n",
        "This solution  redefines the overall conversation flow. Also, the output of the layers are now more consistent and therefore, require less manipulation\n",
        "\n",
        "This solution assumes the input as updated_laptop.csv which has the python dictionalry filled in the last column ,hence no seperate product_map_layer is implemented in this solution as the focus is on function calling API prototype only.\n",
        "\n",
        "This solution uses openai model gpt4o and tools functionality to enable function calling\n",
        "\n",
        "To test this have the updated_laptop.csv and OpenAI_API_Key.txt files in your google drive folder SHOP_ASSIST_ASSIGNMENT under MyDrive\n",
        "\n",
        "Conversations history is written to a text file for further references"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4ukINBvyvQ9",
        "outputId": "a2637b61-b3dd-40c0-e266-942558ac41e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.10-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.10\n"
          ]
        }
      ],
      "source": [
        "#Install openai\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJJVMuodyb2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa91c53-2009-4f2a-9cc2-31a0a4e9d1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "conversation.txt  laptop_data.csv  OpenAI_API_Key.txt  updated_laptop.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/SHOP_ASSIST_ASSIGNMENT')\n",
        "!ls\n",
        "## Import the necessary libraries for building the project\n",
        "import os,json,ast\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
        "from termcolor import colored\n",
        "\n",
        "\n",
        "\n",
        "## Add your OPENAI API KEY\n",
        "openai.api_key = open(\"OpenAI_API_Key.txt\", \"r\").read().strip()\n",
        "os.environ['OPENAI_API_KEY'] = openai.api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnAN5gPkCAfl",
        "outputId": "7f91fc8d-3998-4e91-882f-26e7bec2c336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPROVEMENT#1 - Introducing openAI Function calling API to minimize the manipulations and api calls"
      ],
      "metadata": {
        "id": "Tyk6VpZWVnlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Function Description for the Function Calling API\n",
        "tools = [\n",
        "            {\n",
        "                \"type\": \"function\",\n",
        "                \"function\": {\n",
        "                    \"name\": \"get_laptop_recommendations\",\n",
        "                    \"description\": \"Get the top 3 laptops from the catalogue, that best matches what the user is asking based on 'GPU intensity','Display quality','Portability','Multitasking','Processing speed' & 'Budget\",\n",
        "                    \"parameters\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"properties\": {\n",
        "                            \"gpu intensity\": {\n",
        "                                \"type\": \"string\",\n",
        "                                \"description\": \"The requirement of the user in GPU capacity classfied as low, medium or high\" ,\n",
        "                            },\n",
        "                            \"display quality\": {\n",
        "                                \"type\": \"string\",\n",
        "                                \"description\": \"The requirement of the user for Laptop's Display Quality & capacity classfied as low, medium or high\" ,\n",
        "                            },\n",
        "                            \"portability\": {\n",
        "                                \"type\": \"string\",\n",
        "                                \"description\": \"The requirement of the user for Laptop's portability classfied as low, medium or high\" ,\n",
        "                            },\n",
        "                            \"multitasking\": {\n",
        "                                \"type\": \"string\",\n",
        "                                \"description\": \"The requirement of the user for Laptop's Multitasking classfied as low, medium or high\" ,\n",
        "                            },\n",
        "                            \"processing speed\": {\n",
        "                                \"type\": \"string\",\n",
        "                                \"description\": \"The requirement of the user for Laptop's Processing speed classfied as low, medium or high\" ,\n",
        "                            },\n",
        "                            \"budget\": {\n",
        "                                \"type\": \"integer\",\n",
        "                                \"description\": \"The maximum budget of the user\" ,\n",
        "                            },\n",
        "\n",
        "                        },\n",
        "                        \"required\": [\"GPU intensity\",\"Display quality\",\"Portability\",\"Multitasking\",\"Processing speed\",\"Budget\"],\n",
        "                    },\n",
        "                }\n",
        "            }\n",
        "        ]"
      ],
      "metadata": {
        "id": "OydMvDQPRndt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPROVEMENT#2 - This initializes the variable conversation with the system message. Uses an improved prompt with 50% reduced tokens than the original prompt with simplified ,streamlined instructions and explicit chain of thougts"
      ],
      "metadata": {
        "id": "4zc5pEuCUSuF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZtYd9Sj6PJP"
      },
      "outputs": [],
      "source": [
        "def initialize_conversation():\n",
        "    '''\n",
        "    Returns a list [{\"role\": \"system\", \"content\": system_message}]\n",
        "    '''\n",
        "\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    example_user_dict = {'GPU intensity': \"high\",\n",
        "                        'Display quality':\"high\",\n",
        "                        'Portability': \"low\",\n",
        "                        'Multitasking': \"high\",\n",
        "                        'Processing speed': \"high\",\n",
        "                        'Budget': \"150000\"}\n",
        "\n",
        "\n",
        "    system_message = f\"\"\"\n",
        "        You are an intelligent laptop gadget expert. Your goal is to find the best laptop for a user by asking relevant questions and understanding their profile. You need to confidently fill the values for the keys ('GPU intensity', 'Display quality', 'Portability', 'Multitasking', 'Processing speed', 'Budget') in the Python dictionary based on the user's responses.\n",
        "\n",
        "        The Python dictionary should look like this:\n",
        "        {{'GPU intensity': 'values', 'Display quality': 'values', 'Portability': 'values', 'Multitasking': 'values', 'Processing speed': 'values', 'Budget': 'values'}}\n",
        "\n",
        "        Instructions for filling the dictionary:\n",
        "        - The values for all keys, except 'Budget', should be 'low', 'medium', or 'high' based on the importance stated by the user.\n",
        "        - The value for 'Budget' should be a numerical value extracted from the user's response and must be greater than or equal to 25000 INR. If the budget is below this, inform the user there are no laptops in that range.\n",
        "        - Do not randomly assign values. Ensure all values are inferred from the user's responses.\n",
        "\n",
        "        Chain of Thoughts:\n",
        "        1. Ask questions to understand the user's profile and requirements. Focus on determining the values for the keys ('GPU intensity', 'Display quality', 'Portability', 'Multitasking', 'Processing speed', 'Budget'). If unclear, ask follow-up questions.\n",
        "        2. For keys not filled in the previous step, ask specific questions to gather the necessary information. Use logical questions rather than directly citing the key.\n",
        "        3. Verify if you have correctly filled the values for all keys. If uncertain, ask clarifying questions.\n",
        "\n",
        "        Example User Interaction:\n",
        "        User: \"Hi, I am an editor.\"\n",
        "        Assistant: \"Great! As an editor, you likely require a laptop that can handle demanding tasks. You would need high multitasking capability and a high-end display for better visuals. Are you more involved in video editing, photo editing, or both?\"\n",
        "        User: \"I primarily work with After Effects.\"\n",
        "        Assistant: \"Working with After Effects involves graphics, animations, and rendering, requiring a high GPU. Do you work with high-resolution media files, such as 4K videos?\"\n",
        "        User: \"Yes, sometimes I work with 4K videos.\"\n",
        "        Assistant: \"Processing 4K videos requires a good processor and high GPU. Do you need a lightweight laptop for frequent travel or work primarily from a stationary location?\"\n",
        "        User: \"I travel but do not carry my laptop.\"\n",
        "        Assistant: \"Please let me know your budget for the laptop.\"\n",
        "        User: \"My max budget is 1.5 lakh INR.\"\n",
        "        Assistant: \"{example_user_dict}\"\n",
        "\n",
        "        Start with a short welcome message and encourage the user to share their requirements.\n",
        "        \"\"\"\n",
        "    conversation = [{\"role\": \"system\", \"content\": system_message}]\n",
        "    # conversation = system_message\n",
        "    return conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPROVEMENT#3 - Chat completions api modified to use function calling using tools . this was referred as functions in gpt3.5"
      ],
      "metadata": {
        "id": "CBwVBeWgWnc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
        "\n",
        "def get_chat_model_completions(messages,tools=None, tool_choice=None, model=\"gpt-4o\"):\n",
        "    client = OpenAI()\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            temperature=0, # this is the degree of randomness of the model's output\n",
        "            max_tokens = 500,\n",
        "            tools=tools\n",
        "        )\n",
        "        response = json.loads(response.to_json())\n",
        "        # print(response)\n",
        "        return response[\"choices\"][0][\"message\"]\n",
        "    except Exception as e:\n",
        "        print(f\"Exception: {e}\")\n",
        "        return e"
      ],
      "metadata": {
        "id": "8AvmR3b9Wigk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPROVEMENT#4 - Provide a color coding to each role so that you can differentiate the queries and responses easily in the chatbot"
      ],
      "metadata": {
        "id": "N2Li1eIvXksA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract dictionary from string"
      ],
      "metadata": {
        "id": "ffknMfv0X7Rk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFVCMMSz6GKj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "import re\n",
        "\n",
        "def extract_dictionary_from_string(string):\n",
        "    regex_pattern = r\"\\{[^{}]+\\}\"\n",
        "\n",
        "    dictionary_matches = re.findall(regex_pattern, string)\n",
        "\n",
        "    # Extract the first dictionary match and convert it to lowercase\n",
        "    if dictionary_matches:\n",
        "        dictionary_string = dictionary_matches[0]\n",
        "        dictionary_string = dictionary_string.lower()\n",
        "\n",
        "        # Convert the dictionary string to a dictionary object using ast.literal_eval()\n",
        "        dictionary = ast.literal_eval(dictionary_string)\n",
        "    return dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moderation_check to validate the input for flags . Reduced lines of code to use if else as part of return"
      ],
      "metadata": {
        "id": "mAgsfHBBlbzU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function called moderation_check that takes user_input as a parameter.\n",
        "\n",
        "def moderation_check(user_input):\n",
        "    client = OpenAI()\n",
        "    # Call the OpenAI API to perform moderation on the user's input.\n",
        "    response = client.moderations.create(input=user_input)\n",
        "\n",
        "    # Extract the moderation result from the API response.\n",
        "    moderation_output = response.results[0].flagged\n",
        "    # Check if the input was flagged by the moderation system.\n",
        "    flagged = response.results[0].flagged\n",
        "    return \"Flagged\" if flagged else \"Not Flagged\""
      ],
      "metadata": {
        "id": "EwaQsX1pladh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract the laptop specs from the descriptions\n",
        "\n",
        "Added few shot learnings"
      ],
      "metadata": {
        "id": "7Q5faax5uJys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare laptops with user requests"
      ],
      "metadata": {
        "id": "hhvWvg1ZYCWY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W13nBUM_nv-M"
      },
      "outputs": [],
      "source": [
        "def compare_laptops_with_user(user_req_string):\n",
        "  budget = user_req_string.get('budget', '0')\n",
        "  laptop_df= pd.read_csv('updated_laptop.csv')\n",
        "  filtered_laptops = laptop_df.copy()\n",
        "  filtered_laptops['Price'] = filtered_laptops['Price'].str.replace(',','').astype(int)\n",
        "  filtered_laptops = filtered_laptops[filtered_laptops['Price'] <= budget].copy()\n",
        "\n",
        "  mappings = {\n",
        "          'low': 0,\n",
        "          'medium': 1,\n",
        "          'high': 2\n",
        "      }\n",
        "  # Create 'Score' column in the DataFrame and initialize to 0\n",
        "  filtered_laptops['Score'] = 0\n",
        "  for index, row in filtered_laptops.iterrows():\n",
        "      user_product_match_str = row['laptop_feature']\n",
        "      laptop_values = extract_dictionary_from_string(user_product_match_str)\n",
        "      score = 0\n",
        "\n",
        "      for key, user_value in user_req_string.items():\n",
        "        if key.lower() == 'budget':\n",
        "            continue  # Skip budget comparison\n",
        "        laptop_value = laptop_values.get(key, None)\n",
        "        laptop_mapping = mappings.get(laptop_value.lower(), -1)\n",
        "        user_mapping = mappings.get(user_value.lower(), -1)\n",
        "        if laptop_mapping >= user_mapping:\n",
        "          ### If the laptop value is greater than or equal to the user value the score is incremented by 1\n",
        "          score += 1\n",
        "\n",
        "      filtered_laptops.loc[index, 'Score'] = score\n",
        "\n",
        "  # Sort the laptops by score in descending order and return the top 5 products\n",
        "  top_laptops = filtered_laptops.drop('laptop_feature', axis=1)\n",
        "  top_laptops = top_laptops.sort_values('Score', ascending=False).head(3)\n",
        "\n",
        "  return top_laptops.to_json(orient='records')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validate the recommendations with score"
      ],
      "metadata": {
        "id": "ukZGz_5AYNOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommendation_validation(laptop_recommendation):\n",
        "\n",
        "    data = json.loads(laptop_recommendation)\n",
        "    data1 = []\n",
        "    for i in range(len(data)):\n",
        "      if data[i]['Score'] > 2:\n",
        "        data1.append(data[i])\n",
        "\n",
        "    return json.dumps(data1)"
      ],
      "metadata": {
        "id": "ChCEV0GEYLmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPROVEMENT #5 - Dialogue Management system with less manipulation and reduced api calls\n",
        "\n",
        "1.intent_confirmation_layer and dictionary_present replaced by a simple function call to generate the response always as a python dictionary as mentioned in the function call"
      ],
      "metadata": {
        "id": "316myOFRYSY3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZVtOt4Cmuuw"
      },
      "outputs": [],
      "source": [
        "def dialogue_mgmt_system():\n",
        "    # Initialize the conversation and create the assistant object instance\n",
        "    conversation = initialize_conversation()\n",
        "    introduction = get_chat_model_completions(conversation)[\"content\"]\n",
        "\n",
        "    print(introduction + '\\n')\n",
        "\n",
        "    user_input = \"\"\n",
        "    # Step 1: check moderation\n",
        "    while(user_input != \"exit\"):\n",
        "      user_input = input(\"\")\n",
        "      moderation = moderation_check(user_input)\n",
        "      if moderation == 'Flagged':\n",
        "            display(\"Sorry, this message has been flagged. Please restart your conversation.\")\n",
        "            break\n",
        "      conversation.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "      # Step 2: Pass the user input to GPT\n",
        "      response_assistant = get_chat_model_completions(conversation,tools=tools)\n",
        "\n",
        "      if \"tool_calls\" in list(response_assistant.keys()) and response_assistant[\"tool_calls\"]:\n",
        "        function_called_message = \"\\nThank you for your inputs. Please wait, while I fetch relevant products\\n\"\n",
        "        conversation.append({\"role\": \"assistant\", \"content\": function_called_message})\n",
        "        print(function_called_message)\n",
        "\n",
        "        # Step 3: Extract top3 laptops by calling the external function\n",
        "        tool  = response_assistant[\"tool_calls\"][0]\n",
        "        tool_call_id = tool[\"id\"]\n",
        "        function_name = tool[\"function\"][\"name\"]\n",
        "        function_args = json.loads(tool[\"function\"][\"arguments\"])\n",
        "\n",
        "        top_3_laptops = compare_laptops_with_user(function_args)\n",
        "        function_response = recommendation_validation(top_3_laptops)\n",
        "        if len(function_response) == 0:\n",
        "          print(\"Sorry, we do not have laptops that match your requirements. Connecting you to a human expert.\")\n",
        "          break\n",
        "        # Step 4: send the info on the function call and function response to GPT\n",
        "        conversation.append(response_assistant)\n",
        "        conversation.append(\n",
        "            {\n",
        "                \"tool_call_id\": tool_call_id,\n",
        "                \"role\": \"tool\",\n",
        "                \"name\": function_name,\n",
        "                \"content\": function_response,\n",
        "            }\n",
        "        )\n",
        "        recommendation = get_chat_model_completions(conversation)\n",
        "\n",
        "        conversation.append({\"role\": \"assistant\", \"content\": recommendation[\"content\"]})\n",
        "        print(\"\\n\" +  recommendation[\"content\"] + \"\\n\")\n",
        "        print(\"Enter exit to end the conversation or press enter to continue\\n\")\n",
        "      else:\n",
        "        conversation.append({\"role\": \"assistant\", \"content\": response_assistant[\"content\"]})\n",
        "        print(\"\\n\" +  response_assistant[\"content\"] + \"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "    # Save conversation in a text file\n",
        "    with open(\"conversation.txt\", \"w\") as file:\n",
        "        for message in conversation:\n",
        "            file.write(f\"{message['role']}: {message['content']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ayIzUZvpURv",
        "outputId": "3b98c765-1794-4e0a-9c12-c2305a160bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm here to help you find the perfect laptop. Could you please share a bit about your primary use for the laptop? For example, are you a gamer, a professional editor, a student, or do you have other specific needs? Additionally, let me know your budget range.\n",
            "\n",
            "i am a professional editor\n",
            "\n",
            "Great! As a professional editor, you likely require a laptop that can handle demanding tasks. You would need high multitasking capability and a high-end display for better visuals. Are you more involved in video editing, photo editing, or both?\n",
            "\n",
            "video editing\n",
            "\n",
            "Working with video editing involves graphics, animations, and rendering, which require a high GPU. Do you work with high-resolution media files, such as 4K videos?\n",
            "\n",
            "4k\n",
            "\n",
            "Processing 4K videos requires a good processor and high GPU. Do you need a lightweight laptop for frequent travel, or do you work primarily from a stationary location?\n",
            "\n",
            "stationary\n",
            "\n",
            "Got it. Since you work primarily from a stationary location, portability is less of a concern. \n",
            "\n",
            "Please let me know your budget for the laptop.\n",
            "\n",
            "60000\n",
            "\n",
            "Thank you for your inputs. Please wait, while I fetch relevant products\n",
            "\n",
            "\n",
            "Based on your requirements and budget, here are two laptop recommendations that fit your needs:\n",
            "\n",
            "### 1. MSI GL65\n",
            "- **Processor**: Intel Core i7 (2.6 GHz)\n",
            "- **RAM**: 16GB\n",
            "- **Storage**: HDD+SSD\n",
            "- **Display**: 15.6\" IPS, 1920x1080 resolution\n",
            "- **Graphics**: NVIDIA GTX\n",
            "- **Operating System**: Windows 10\n",
            "- **Weight**: 2.3 kg\n",
            "- **Special Features**: RGB Keyboard\n",
            "- **Warranty**: 2 years\n",
            "- **Battery Life**: 4 hours\n",
            "- **Price**: 55,000 INR\n",
            "- **Description**: The MSI GL65 is a high-performance laptop designed for gaming enthusiasts. It offers exceptional processing power, ample memory, and fast data access. The vivid display and excellent visual performance make it suitable for video editing. The RGB keyboard adds a personalized touch to your setup.\n",
            "\n",
            "### 2. Lenovo ThinkPad\n",
            "- **Processor**: AMD Ryzen 7 (3.0 GHz)\n",
            "- **RAM**: 16GB\n",
            "- **Storage**: SSD\n",
            "- **Display**: 14\" IPS, 2560x1440 resolution\n",
            "- **Graphics**: NVIDIA GTX\n",
            "- **Operating System**: Linux\n",
            "- **Weight**: 1.6 kg\n",
            "- **Special Features**: Backlit Keyboard\n",
            "- **Warranty**: 3 years\n",
            "- **Battery Life**: 6 hours\n",
            "- **Price**: 60,000 INR\n",
            "- **Description**: The Lenovo ThinkPad is a powerful laptop designed for professional users. It offers strong processing capabilities, smooth multitasking, and fast storage access. The sharp visuals and accurate colors make it ideal for video editing. The lightweight design and backlit keyboard enhance portability and usability.\n",
            "\n",
            "### Summary\n",
            "- **MSI GL65**: Better for those who prefer a larger screen and Windows OS.\n",
            "- **Lenovo ThinkPad**: Better for those who prefer a higher resolution display and Linux OS.\n",
            "\n",
            "Would you like more details on either of these options, or do you have any other specific preferences?\n",
            "\n",
            "Enter exit to end the conversation or press enter to continue\n",
            "\n",
            "exit\n",
            "\n",
            "If you have any more questions in the future, feel free to ask. Have a great day!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dialogue_mgmt_system()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAZSEx4e0gbA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}